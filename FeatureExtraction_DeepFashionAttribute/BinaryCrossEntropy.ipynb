{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 16\n",
    "LR_RATE = 0.001\n",
    "MODEL_NAME = 'vit_small_patch32_224.augreg_in21k_ft_in1k'\n",
    "THRESHOLD = 0.5\n",
    "NUM_LABELS = 20 #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, timm_model_name):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        model = timm.create_model(timm_model_name, pretrained=True)\n",
    "        self.cnn_model = timm.create_model(timm_model_name, pretrained=True)\n",
    "\n",
    "        for param in self.cnn_model.parameters(): # Freeze all the layers of the backbone\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.num_features = self.cnn_model.num_features  # Extract number of features from the model\n",
    "        self.cnn_model.reset_classifier(num_classes=0)  # Remove the final classifier layer\n",
    "        \n",
    "        self.D1 = nn.Linear(self.num_features, 512)\n",
    "        self.BN_1 = nn.BatchNorm1d(512)\n",
    "        self.D2 = nn.Linear(512, 128)\n",
    "        self.BN_2 = nn.BatchNorm1d(128)\n",
    "        self.out = nn.Linear(128, NUM_LABELS)  # Output 1000-long boolean vector\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.D1(x)\n",
    "        x = self.BN_1(x)\n",
    "        x = nn.functional.leaky_relu(x)\n",
    "        \n",
    "        x = self.D2(x)\n",
    "        x = self.BN_2(x)\n",
    "        x = nn.functional.leaky_relu(x)\n",
    "        \n",
    "        out = self.out(x)\n",
    "        \n",
    "        # Apply sigmoid activation to produce boolean values\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for image and 1000 length attribute vector.\n",
    "class ImageAttributeDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx]['image_name']\n",
    "        img_path = self.base_path + img_name  # Concatenate base path with image name\n",
    "        attribute_vector = self.dataframe.iloc[idx][1:].values.astype('float64')\n",
    "        \n",
    "        # Load image from file\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # Convert attribute vector to tensor\n",
    "        attribute_tensor = torch.tensor(attribute_vector, dtype=torch.float32)\n",
    "        attribute_tensor = attribute_tensor.type(torch.LongTensor)\n",
    "        \n",
    "        return img, attribute_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, saturation=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilabel conf matrix\n",
    "def metrics_df(data):\n",
    "    df = pd.DataFrame(columns=[\"type\", \"precision\", \"recall\", 'f1-score', 'support'])\n",
    "    metrics = ['micro avg', 'macro avg', 'samples avg', 'weighted avg']\n",
    "\n",
    "    for metric in metrics:\n",
    "        precision = data[metric]['precision']\n",
    "        recall = data[metric]['recall']\n",
    "        f1_score = data[metric]['f1-score']\n",
    "        support = data[metric]['support']\n",
    "\n",
    "        df.loc[-1] = [metric, \"%.5f\" %precision, \"%.5f\" %recall, \"%.5f\" %f1_score, \"%d\" %support]  # adding a row\n",
    "        df.index = df.index + 1  # shifting index\n",
    "        df = df.sort_index()  # sorting by index\n",
    "    \n",
    "    df_no = df.reset_index(drop=True)\n",
    "\n",
    "    print(tabulate(df_no, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>evaluation_status</th>\n",
       "      <th>attr_0</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>...</th>\n",
       "      <th>attr_990</th>\n",
       "      <th>attr_991</th>\n",
       "      <th>attr_992</th>\n",
       "      <th>attr_993</th>\n",
       "      <th>attr_994</th>\n",
       "      <th>attr_995</th>\n",
       "      <th>attr_996</th>\n",
       "      <th>attr_997</th>\n",
       "      <th>attr_998</th>\n",
       "      <th>attr_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image_name evaluation_status  attr_0  \\\n",
       "0  img/Sheer_Pleated-Front_Blouse/img_00000001.jpg             train       0   \n",
       "1  img/Sheer_Pleated-Front_Blouse/img_00000002.jpg             train       0   \n",
       "2  img/Sheer_Pleated-Front_Blouse/img_00000003.jpg               val       0   \n",
       "3  img/Sheer_Pleated-Front_Blouse/img_00000004.jpg             train       0   \n",
       "4  img/Sheer_Pleated-Front_Blouse/img_00000005.jpg              test       0   \n",
       "\n",
       "   attr_1  attr_2  attr_3  attr_4  attr_5  attr_6  attr_7  ...  attr_990  \\\n",
       "0       0       0       0       0       0       0       0  ...         0   \n",
       "1       0       0       0       0       0       0       0  ...         0   \n",
       "2       0       0       0       0       0       0       0  ...         0   \n",
       "3       0       0       0       0       0       0       0  ...         0   \n",
       "4       0       0       0       0       0       0       0  ...         0   \n",
       "\n",
       "   attr_991  attr_992  attr_993  attr_994  attr_995  attr_996  attr_997  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   attr_998  attr_999  \n",
       "0         0         0  \n",
       "1         0         0  \n",
       "2         0         0  \n",
       "3         0         0  \n",
       "4         0         0  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exact Paths\n",
    "PATH_ATTR_FILE = \"C:/Users/hecan/Desktop/Project/Benchmark/Anno/list_attr_img.txt\"\n",
    "PATH_PART_FILE = \"C:/Users/hecan/Desktop/Project/Benchmark/Eval/list_eval_partition.txt\"\n",
    "BASE_PATH = \"C:/Users/hecan/Desktop/Project/Benchmark/\"\n",
    "DATAFRAME_PATH = BASE_PATH + \"dataframe.csv\"\n",
    "\n",
    "all_df = pd.read_csv('dataframe.csv')\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top x most used class filter\n",
    "def filter_data(all_df, r):\n",
    "    # Extract the `attr` columns\n",
    "    attr_columns = [col for col in all_df.columns if col.startswith('attr_')]\n",
    "    attr_df = all_df[attr_columns]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    attr_array = attr_df.values\n",
    "\n",
    "    # Calculate class frequencies\n",
    "    class_counts = np.sum(attr_array, axis=0)\n",
    "\n",
    "    threshold = np.percentile(class_counts, r)\n",
    "    attr_100_list = list()\n",
    "    class_counts_x = list()\n",
    "\n",
    "    for i in range(len(class_counts)):\n",
    "        if class_counts[i] >= threshold:\n",
    "            attr_100_list.append(f\"attr_{i}\")\n",
    "            class_counts_x.append(class_counts[i])\n",
    "\n",
    "    cols = [\"image_name\", \"evaluation_status\"]\n",
    "    cols.extend(attr_100_list)\n",
    "    filtered_df = all_df[cols]\n",
    "    return filtered_df, attr_100_list, class_counts_x\n",
    "\n",
    "filtered_df, attr_100_list, class_counts = filter_data(all_df, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test_df:  40000\n",
      "Length of train_df:  209222\n",
      "Length of val_df:  40000\n"
     ]
    }
   ],
   "source": [
    "# Dataset Prepare\n",
    "train_df_und = filtered_df[filtered_df['evaluation_status'] == 'train']\n",
    "test_df_und = filtered_df[filtered_df['evaluation_status'] == 'test']\n",
    "val_df_und = filtered_df[filtered_df['evaluation_status'] == 'val']\n",
    "\n",
    "train_df = train_df_und.drop(columns=['evaluation_status'])\n",
    "test_df = test_df_und.drop(columns=['evaluation_status'])\n",
    "val_df = val_df_und.drop(columns=['evaluation_status'])\n",
    "\n",
    "print(\"Length of test_df: \", len(test_df)) #40k test, rest train\n",
    "print(\"Length of train_df: \", len(train_df)) #40k test, rest train\n",
    "print(\"Length of val_df: \", len(val_df)) #40k test, rest train\n",
    "\n",
    "train_dataset = ImageAttributeDataset(dataframe=train_df, base_path=BASE_PATH, transform=train_transform)\n",
    "test_dataset = ImageAttributeDataset(dataframe=test_df, base_path=BASE_PATH, transform=transform)\n",
    "val_dataset = ImageAttributeDataset(dataframe=val_df, base_path=BASE_PATH, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# Extract the `attr` columns\n",
    "attr_columns = [col for col in filtered_df.columns if col.startswith('attr_')]\n",
    "attr_df = filtered_df[attr_columns]\n",
    "\n",
    "# Convert to numpy array\n",
    "attr_array = attr_df.values\n",
    "\n",
    "# Calculate class frequencies\n",
    "class_counts = np.sum(attr_array, axis=0)\n",
    "\n",
    "def calculate_pos_weights(class_counts):\n",
    "  pos_weights = np.ones_like(class_counts)\n",
    "  neg_counts = [len(all_df)-pos_count for pos_count in class_counts]\n",
    "  print(len(neg_counts))\n",
    "  for cdx, ccng in enumerate(zip(class_counts,  neg_counts)):\n",
    "    pos_weights[cdx] = ccng[1] / (ccng[0] + 1e-5)\n",
    "\n",
    "  return torch.as_tensor(pos_weights, dtype=torch.float).to(device)\n",
    "\n",
    "weights = calculate_pos_weights(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = SiameseModel(timm_model_name=MODEL_NAME)\n",
    "\n",
    "# Assuming optimizer is your optimizer (e.g., Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13077 [00:00<?, ?batch/s]c:\\Users\\hecan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\timm\\models\\vision_transformer.py:91: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  x = F.scaled_dot_product_attention(\n",
      "100%|██████████| 13077/13077 [21:53<00:00,  9.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1075 Validation loss: 0.1351\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.61538 |  0.14653 |    0.20369 |     36389 |\n",
      "| samples avg  |     0.92954 |  0.50311 |    0.47835 |     36389 |\n",
      "| macro avg    |     0.64717 |  0.11474 |    0.16228 |     36389 |\n",
      "| micro avg    |     0.61684 |  0.14653 |    0.2368  |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [18:59<00:00, 11.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1078 Validation loss: 0.1333\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.66813 |  0.15112 |    0.20565 |     36389 |\n",
      "| samples avg  |     0.93175 |  0.50631 |    0.48225 |     36389 |\n",
      "| macro avg    |     0.71009 |  0.11221 |    0.15352 |     36389 |\n",
      "| micro avg    |     0.63484 |  0.15112 |    0.24412 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [18:56<00:00, 11.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1184 Validation loss: 0.1317\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.63339 |  0.16859 |    0.232   |     36389 |\n",
      "| samples avg  |     0.92645 |  0.51441 |    0.4888  |     36389 |\n",
      "| macro avg    |     0.65874 |  0.13461 |    0.18817 |     36389 |\n",
      "| micro avg    |     0.63195 |  0.16859 |    0.26618 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [19:10<00:00, 11.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1007 Validation loss: 0.1309\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.64618 |  0.16379 |    0.22343 |     36389 |\n",
      "| samples avg  |     0.93052 |  0.51184 |    0.48854 |     36389 |\n",
      "| macro avg    |     0.65951 |  0.1281  |    0.17795 |     36389 |\n",
      "| micro avg    |     0.64419 |  0.16379 |    0.26117 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [19:04<00:00, 11.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1039 Validation loss: 0.1308\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.62719 |  0.18607 |    0.2501  |     36389 |\n",
      "| samples avg  |     0.91922 |  0.52491 |    0.49498 |     36389 |\n",
      "| macro avg    |     0.64118 |  0.14284 |    0.19743 |     36389 |\n",
      "| micro avg    |     0.63092 |  0.18607 |    0.28739 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [19:00<00:00, 11.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0964 Validation loss: 0.1308\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.60814 |  0.19454 |    0.25761 |     36389 |\n",
      "| samples avg  |     0.91437 |  0.52943 |    0.49713 |     36389 |\n",
      "| macro avg    |     0.61428 |  0.1497  |    0.20456 |     36389 |\n",
      "| micro avg    |     0.62718 |  0.19454 |    0.29696 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [19:07<00:00, 11.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1044 Validation loss: 0.1303\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.58983 |  0.20347 |    0.26458 |     36389 |\n",
      "| samples avg  |     0.9084  |  0.53438 |    0.49976 |     36389 |\n",
      "| macro avg    |     0.5794  |  0.15618 |    0.21219 |     36389 |\n",
      "| micro avg    |     0.6187  |  0.20347 |    0.30623 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [19:06<00:00, 11.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1058 Validation loss: 0.1307\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.5973  |  0.19685 |    0.26789 |     36389 |\n",
      "| samples avg  |     0.91025 |  0.53011 |    0.49557 |     36389 |\n",
      "| macro avg    |     0.59863 |  0.15278 |    0.21611 |     36389 |\n",
      "| micro avg    |     0.6157  |  0.19685 |    0.29832 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [18:59<00:00, 11.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1027 Validation loss: 0.1302\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.58372 |  0.20677 |    0.26976 |     36389 |\n",
      "| samples avg  |     0.90553 |  0.53694 |    0.50141 |     36389 |\n",
      "| macro avg    |     0.57301 |  0.15905 |    0.21573 |     36389 |\n",
      "| micro avg    |     0.61506 |  0.20677 |    0.30949 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13077/13077 [18:59<00:00, 11.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0867 Validation loss: 0.1307\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.588   |  0.1853  |    0.25618 |     36389 |\n",
      "| samples avg  |     0.9181  |  0.52552 |    0.49445 |     36389 |\n",
      "| macro avg    |     0.5752  |  0.15222 |    0.21265 |     36389 |\n",
      "| micro avg    |     0.63291 |  0.1853  |    0.28667 |     36389 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop with validation\n",
    "num_epochs = 10\n",
    "model.to(device)\n",
    "\n",
    "# Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    with tqdm(train_loader, unit=\"batch\") as t:\n",
    "        for batch_idx, (images, attributes) in enumerate(t):\n",
    "            images, attributes = images.to(device), attributes.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, attributes.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * attributes.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images_val, attributes_val in val_loader:\n",
    "            images_val, attributes_val = images_val.to(device), attributes_val.to(device)\n",
    "            val_outputs = model(images_val)\n",
    "            loss = criterion(val_outputs, attributes_val.float())\n",
    "            val_loss += loss.item() * attributes_val.size(0)\n",
    "            \n",
    "            # Convert outputs to binary predictions using a threshold (e.g., 0.5)\n",
    "            predicted = val_outputs > THRESHOLD\n",
    "            \n",
    "            # Convert tensors to numpy arrays\n",
    "            attributes_val_np = attributes_val.cpu().numpy()\n",
    "            predicted_np = predicted.cpu().numpy()\n",
    "            \n",
    "            # Append true labels and predicted labels to the lists\n",
    "            true_labels.extend(attributes_val_np)\n",
    "            predicted_labels.extend(predicted_np)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    print(f\"Training loss: {loss.item():.4f}\", f\"Validation loss: {val_loss:.4f}\")\n",
    "    d = classification_report(true_labels, predicted_labels, target_names=attr_100_list, output_dict=True, zero_division=1)\n",
    "    df_metrics = metrics_df(d)\n",
    "\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bce_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.56618 |  0.22357 |    0.29329 |     36128 |\n",
      "| samples avg  |     0.89143 |  0.54783 |    0.50336 |     36128 |\n",
      "| macro avg    |     0.56116 |  0.18363 |    0.247   |     36128 |\n",
      "| micro avg    |     0.60012 |  0.22357 |    0.32577 |     36128 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "0.1303184690363705\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Validation phase\n",
    "model.eval()\n",
    "loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images_test, attributes_test in test_loader:\n",
    "        images_test, attributes_test = images_test.to(device), attributes_test.to(device)\n",
    "        test_outputs = model(images_test)\n",
    "        test_loss = criterion(test_outputs, attributes_test.float())\n",
    "        loss += test_loss.item()\n",
    "        \n",
    "        # Convert outputs to binary predictions using a threshold (e.g., 0.5)\n",
    "        predicted = test_outputs > 0.45\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        attributes_test_np = attributes_test.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        \n",
    "        # Append true labels and predicted labels to the lists\n",
    "        true_labels.extend(attributes_test_np)\n",
    "        predicted_labels.extend(predicted_np)\n",
    "\n",
    "loss /= len(test_loader)\n",
    "\n",
    "# Compute confusion matrix\n",
    "d = classification_report(true_labels, predicted_labels, target_names=attr_100_list, output_dict=True, zero_division=1)\n",
    "df_metrics = metrics_df(d)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.53058 |  0.26647 |    0.3267  |     36128 |\n",
      "| samples avg  |     0.8537  |  0.57297 |    0.50727 |     36128 |\n",
      "| macro avg    |     0.52509 |  0.21757 |    0.27635 |     36128 |\n",
      "| micro avg    |     0.55767 |  0.26647 |    0.36062 |     36128 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "0.1303184690363705\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Validation phase\n",
    "model.eval()\n",
    "loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images_test, attributes_test in test_loader:\n",
    "        images_test, attributes_test = images_test.to(device), attributes_test.to(device)\n",
    "        test_outputs = model(images_test)\n",
    "        test_loss = criterion(test_outputs, attributes_test.float())\n",
    "        loss += test_loss.item()\n",
    "        \n",
    "        # Convert outputs to binary predictions using a threshold (e.g., 0.5)\n",
    "        predicted = test_outputs > 0.4\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        attributes_test_np = attributes_test.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        \n",
    "        # Append true labels and predicted labels to the lists\n",
    "        true_labels.extend(attributes_test_np)\n",
    "        predicted_labels.extend(predicted_np)\n",
    "\n",
    "loss /= len(test_loader)\n",
    "\n",
    "# Compute confusion matrix\n",
    "d = classification_report(true_labels, predicted_labels, target_names=attr_100_list, output_dict=True, zero_division=1)\n",
    "df_metrics = metrics_df(d)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.58741 |  0.18396 |    0.25565 |     36128 |\n",
      "| samples avg  |     0.92054 |  0.52479 |    0.49575 |     36128 |\n",
      "| macro avg    |     0.57606 |  0.15261 |    0.21489 |     36128 |\n",
      "| micro avg    |     0.63996 |  0.18396 |    0.28577 |     36128 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "0.1303184690363705\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Validation phase\n",
    "model.eval()\n",
    "loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images_test, attributes_test in test_loader:\n",
    "        images_test, attributes_test = images_test.to(device), attributes_test.to(device)\n",
    "        test_outputs = model(images_test)\n",
    "        test_loss = criterion(test_outputs, attributes_test.float())\n",
    "        loss += test_loss.item()\n",
    "        \n",
    "        # Convert outputs to binary predictions using a threshold (e.g., 0.5)\n",
    "        predicted = test_outputs > 0.5\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        attributes_test_np = attributes_test.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        \n",
    "        # Append true labels and predicted labels to the lists\n",
    "        true_labels.extend(attributes_test_np)\n",
    "        predicted_labels.extend(predicted_np)\n",
    "\n",
    "loss /= len(test_loader)\n",
    "\n",
    "# Compute confusion matrix\n",
    "d = classification_report(true_labels, predicted_labels, target_names=attr_100_list, output_dict=True, zero_division=1)\n",
    "df_metrics = metrics_df(d)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.65405 |  0.14795 |    0.21566 |     36128 |\n",
      "| samples avg  |     0.94383 |  0.5039  |    0.48494 |     36128 |\n",
      "| macro avg    |     0.6666  |  0.12569 |    0.18362 |     36128 |\n",
      "| micro avg    |     0.67693 |  0.14795 |    0.24282 |     36128 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "0.1303184690363705\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Validation phase\n",
    "model.eval()\n",
    "loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images_test, attributes_test in test_loader:\n",
    "        images_test, attributes_test = images_test.to(device), attributes_test.to(device)\n",
    "        test_outputs = model(images_test)\n",
    "        test_loss = criterion(test_outputs, attributes_test.float())\n",
    "        loss += test_loss.item()\n",
    "        \n",
    "        # Convert outputs to binary predictions using a threshold (e.g., 0.5)\n",
    "        predicted = test_outputs > 0.55\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        attributes_test_np = attributes_test.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        \n",
    "        # Append true labels and predicted labels to the lists\n",
    "        true_labels.extend(attributes_test_np)\n",
    "        predicted_labels.extend(predicted_np)\n",
    "\n",
    "loss /= len(test_loader)\n",
    "\n",
    "# Compute confusion matrix\n",
    "d = classification_report(true_labels, predicted_labels, target_names=attr_100_list, output_dict=True, zero_division=1)\n",
    "df_metrics = metrics_df(d)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.69959 |  0.11755 |    0.17686 |     36128 |\n",
      "| samples avg  |     0.96099 |  0.4861  |    0.47481 |     36128 |\n",
      "| macro avg    |     0.72474 |  0.10255 |    0.15371 |     36128 |\n",
      "| micro avg    |     0.7127  |  0.11755 |    0.20182 |     36128 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "0.1303184690363705\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Validation phase\n",
    "model.eval()\n",
    "loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images_test, attributes_test in test_loader:\n",
    "        images_test, attributes_test = images_test.to(device), attributes_test.to(device)\n",
    "        test_outputs = model(images_test)\n",
    "        test_loss = criterion(test_outputs, attributes_test.float())\n",
    "        loss += test_loss.item()\n",
    "        \n",
    "        # Convert outputs to binary predictions using a threshold (e.g., 0.5)\n",
    "        predicted = test_outputs > 0.6\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        attributes_test_np = attributes_test.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        \n",
    "        # Append true labels and predicted labels to the lists\n",
    "        true_labels.extend(attributes_test_np)\n",
    "        predicted_labels.extend(predicted_np)\n",
    "\n",
    "loss /= len(test_loader)\n",
    "\n",
    "# Compute confusion matrix\n",
    "d = classification_report(true_labels, predicted_labels, target_names=attr_100_list, output_dict=True, zero_division=1)\n",
    "df_metrics = metrics_df(d)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_model = SiameseModel(MODEL_NAME)\n",
    "temp_model.load_state_dict(torch.load('bce_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseModel(\n",
       "  (cnn_model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 384, kernel_size=(32, 32), stride=(32, 32))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (D1): Linear(in_features=384, out_features=512, bias=True)\n",
       "  (BN_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (D2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (BN_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (out): Linear(in_features=128, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------+------------+-----------+\n",
      "| type         |   precision |   recall |   f1-score |   support |\n",
      "|--------------+-------------+----------+------------+-----------|\n",
      "| weighted avg |     0.44299 |  0.3626  |    0.37743 |     36128 |\n",
      "| samples avg  |     0.7416  |  0.63012 |    0.49423 |     36128 |\n",
      "| macro avg    |     0.42747 |  0.29693 |    0.32391 |     36128 |\n",
      "| micro avg    |     0.47146 |  0.3626  |    0.40993 |     36128 |\n",
      "+--------------+-------------+----------+------------+-----------+\n",
      "0.13068277368119452\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store true labels and predicted labels for the entire validation set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Validation phase\n",
    "temp_model.eval()\n",
    "loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images_test, attributes_test in test_loader:\n",
    "        images_test, attributes_test = images_test.to(device), attributes_test.to(device)\n",
    "        test_outputs = temp_model(images_test)\n",
    "        test_loss = criterion(test_outputs, attributes_test.float())\n",
    "        loss += test_loss.item()\n",
    "        \n",
    "        # Convert outputs to binary predictions using a threshold (e.g., 0.5)\n",
    "        predicted = test_outputs > 0.3\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        attributes_test_np = attributes_test.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        \n",
    "        # Append true labels and predicted labels to the lists\n",
    "        true_labels.extend(attributes_test_np)\n",
    "        predicted_labels.extend(predicted_np)\n",
    "\n",
    "loss /= len(test_loader)\n",
    "\n",
    "# Compute confusion matrix\n",
    "d = classification_report(true_labels, predicted_labels, target_names=attr_100_list, output_dict=True, zero_division=1)\n",
    "df_metrics = metrics_df(d)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
